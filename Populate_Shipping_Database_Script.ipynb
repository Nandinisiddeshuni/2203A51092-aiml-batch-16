{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nandinisiddeshuni/CHESS-Datasetsss/blob/main/Populate_Shipping_Database_Script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "DATABASE_NAME = 'shipping.db'\n",
        "SPREADSHEET_DIR = 'forage-walmart-task-4' # Assuming you've cloned the repo into this folder\n",
        "\n",
        "# --- Database Schema (Assumed based on requirements and common ERD practices) ---\n",
        "# The script will create these tables if they don't exist.\n",
        "SCHEMA_SQL = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS products (\n",
        "    product_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    name TEXT NOT NULL,\n",
        "    manufacturer TEXT NOT NULL,\n",
        "    type TEXT NOT NULL, -- e.g., 'food', 'toy', 'apparel'\n",
        "    weight REAL,\n",
        "    flavor TEXT,\n",
        "    health_condition TEXT,\n",
        "    material TEXT,\n",
        "    durability TEXT,\n",
        "    color TEXT,\n",
        "    size TEXT,\n",
        "    care_instructions TEXT,\n",
        "    UNIQUE(name, manufacturer, type) -- Ensures no duplicate product entries\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS shipments (\n",
        "    shipment_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    shipping_identifier TEXT UNIQUE NOT NULL,\n",
        "    origin TEXT NOT NULL,\n",
        "    destination TEXT NOT NULL,\n",
        "    origin_zip TEXT NOT NULL,\n",
        "    destination_zip TEXT NOT NULL,\n",
        "    shipment_date TEXT NOT NULL -- Storing as TEXT for simplicity, could be DATE\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS shipment_items (\n",
        "    shipment_item_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    shipment_id INTEGER NOT NULL,\n",
        "    product_id INTEGER NOT NULL,\n",
        "    quantity INTEGER NOT NULL,\n",
        "    FOREIGN KEY (shipment_id) REFERENCES shipments(shipment_id),\n",
        "    FOREIGN KEY (product_id) REFERENCES products(product_id)\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "def setup_database(db_path):\n",
        "    \"\"\"Connects to the SQLite database and ensures tables are created.\"\"\"\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.executescript(SCHEMA_SQL)\n",
        "    conn.commit()\n",
        "    print(f\"Database '{db_path}' schema ensured.\")\n",
        "    return conn\n",
        "\n",
        "def get_or_insert_product(cursor, product_data):\n",
        "    \"\"\"\n",
        "    Gets product_id if product exists, otherwise inserts and returns new product_id.\n",
        "    Handles different product types and their specific attributes.\n",
        "    \"\"\"\n",
        "    # Extract common attributes\n",
        "    name = product_data.get('product_name')\n",
        "    manufacturer = product_data.get('manufacturer')\n",
        "    product_type = product_data.get('product_type')\n",
        "\n",
        "    # Try to find existing product\n",
        "    cursor.execute(\n",
        "        \"SELECT product_id FROM products WHERE name = ? AND manufacturer = ? AND type = ?\",\n",
        "        (name, manufacturer, product_type)\n",
        "    )\n",
        "    product_id = cursor.fetchone()\n",
        "    if product_id:\n",
        "        return product_id[0]\n",
        "\n",
        "    # If not found, prepare data for insertion. Handle None for nullable columns.\n",
        "    weight = product_data.get('weight')\n",
        "    flavor = product_data.get('flavor')\n",
        "    health_condition = product_data.get('target_health_condition')\n",
        "    material = product_data.get('material')\n",
        "    durability = product_data.get('durability')\n",
        "    color = product_data.get('color')\n",
        "    size = product_data.get('size')\n",
        "    care_instructions = product_data.get('specific_care_instructions') # Corrected column name\n",
        "\n",
        "    insert_sql = \"\"\"\n",
        "    INSERT INTO products (name, manufacturer, type, weight, flavor, health_condition,\n",
        "                          material, durability, color, size, care_instructions)\n",
        "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "    \"\"\"\n",
        "    cursor.execute(insert_sql, (\n",
        "        name, manufacturer, product_type, weight, flavor, health_condition,\n",
        "        material, durability, color, size, care_instructions\n",
        "    ))\n",
        "    return cursor.lastrowid\n",
        "\n",
        "def process_spreadsheet0(file_path, conn):\n",
        "    \"\"\"Reads spreadsheet0.xlsx and populates the products table.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_excel(file_path)\n",
        "        print(f\"Processing {os.path.basename(file_path)}...\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {file_path} not found. Skipping.\")\n",
        "        return\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "    products_inserted = 0\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # Prepare product data dictionary, handling varying column names\n",
        "        product_data = {\n",
        "            'product_name': row.get('product_name'),\n",
        "            'manufacturer': row.get('manufacturer'),\n",
        "            'product_type': row.get('product_type'),\n",
        "            'weight': row.get('weight'),\n",
        "            'flavor': row.get('flavor'),\n",
        "            'target_health_condition': row.get('target_health_condition'),\n",
        "            'material': row.get('material'),\n",
        "            'durability': row.get('durability'),\n",
        "            'color': row.get('color'),\n",
        "            'size': row.get('size'),\n",
        "            'specific_care_instructions': row.get('specific_care_instructions') # Matches spreadsheet column\n",
        "        }\n",
        "\n",
        "        # Ensure common required fields are not None\n",
        "        if product_data['product_name'] is None or product_data['manufacturer'] is None or product_data['product_type'] is None:\n",
        "            print(f\"Skipping row {index} in {file_path} due to missing required product data: {product_data}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            get_or_insert_product(cursor, product_data)\n",
        "            products_inserted += 1\n",
        "        except sqlite3.IntegrityError as e:\n",
        "            # This should ideally not happen if UNIQUE constraint is well-defined\n",
        "            # and get_or_insert_product logic is correct for existing products.\n",
        "            # However, if new products from spreadsheet0 somehow conflict on other properties, this catches it.\n",
        "            print(f\"Integrity Error inserting product from row {index}: {row['product_name']} - {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing product row {index} in {file_path}: {e}\")\n",
        "\n",
        "    conn.commit()\n",
        "    print(f\"Finished processing {os.path.basename(file_path)}. {products_inserted} unique products processed.\")\n",
        "\n",
        "def process_shipment_data(spreadsheet1_path, spreadsheet2_path, conn):\n",
        "    \"\"\"\n",
        "    Reads spreadsheet1.xlsx and spreadsheet2.xlsx, merges them,\n",
        "    and populates the shipments and shipment_items tables.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df1 = pd.read_excel(spreadsheet1_path)\n",
        "        df2 = pd.read_excel(spreadsheet2_path)\n",
        "        print(f\"Processing {os.path.basename(spreadsheet1_path)} and {os.path.basename(spreadsheet2_path)}...\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: One or both shipment spreadsheets not found ({e}). Skipping.\")\n",
        "        return\n",
        "\n",
        "    # Merge the two dataframes on 'shipping_identifier'\n",
        "    # Use 'inner' merge to ensure we only process shipments with complete data\n",
        "    merged_df = pd.merge(df1, df2, on='shipping_identifier', how='inner')\n",
        "    print(f\"Merged dataframe contains {len(merged_df)} rows for shipment processing.\")\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "    shipments_processed = 0\n",
        "    items_inserted = 0\n",
        "\n",
        "    # Track inserted shipments to avoid re-inserting shipment header data\n",
        "    inserted_shipments = set()\n",
        "\n",
        "    # Iterate through the merged dataframe\n",
        "    for index, row in merged_df.iterrows():\n",
        "        shipping_identifier = row.get('shipping_identifier')\n",
        "\n",
        "        if shipping_identifier is None:\n",
        "            print(f\"Skipping row {index} due to missing shipping_identifier.\")\n",
        "            continue\n",
        "\n",
        "        # --- Process Shipment Header (if not already processed) ---\n",
        "        if shipping_identifier not in inserted_shipments:\n",
        "            origin = row.get('origin')\n",
        "            destination = row.get('destination')\n",
        "            origin_zip = row.get('origin_zip')\n",
        "            destination_zip = row.get('destination_zip')\n",
        "            shipment_date = str(row.get('shipment_date')) # Convert date to string for TEXT column\n",
        "\n",
        "            if any(val is None for val in [origin, destination, origin_zip, destination_zip, shipment_date]):\n",
        "                print(f\"Skipping shipment {shipping_identifier} due to missing header data.\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                cursor.execute(\n",
        "                    \"\"\"\n",
        "                    INSERT INTO shipments (shipping_identifier, origin, destination, origin_zip, destination_zip, shipment_date)\n",
        "                    VALUES (?, ?, ?, ?, ?, ?)\n",
        "                    ON CONFLICT(shipping_identifier) DO NOTHING\n",
        "                    \"\"\",\n",
        "                    (shipping_identifier, origin, destination, origin_zip, destination_zip, shipment_date)\n",
        "                )\n",
        "                if cursor.rowcount > 0: # Check if a new row was inserted\n",
        "                    shipments_processed += 1\n",
        "                inserted_shipments.add(shipping_identifier) # Mark as processed\n",
        "            except sqlite3.IntegrityError as e:\n",
        "                # This could happen if ON CONFLICT DO NOTHING fails for some reason\n",
        "                print(f\"Integrity Error inserting shipment {shipping_identifier}: {e}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing shipment header for {shipping_identifier}: {e}\")\n",
        "\n",
        "        # --- Retrieve Shipment ID ---\n",
        "        cursor.execute(\"SELECT shipment_id FROM shipments WHERE shipping_identifier = ?\", (shipping_identifier,))\n",
        "        shipment_id_result = cursor.fetchone()\n",
        "        if not shipment_id_result:\n",
        "            print(f\"Could not retrieve shipment_id for {shipping_identifier}. Skipping shipment item.\")\n",
        "            continue\n",
        "        shipment_id = shipment_id_result[0]\n",
        "\n",
        "        # --- Process Shipment Item ---\n",
        "        product_name = row.get('product_name')\n",
        "        manufacturer = row.get('manufacturer')\n",
        "        quantity = row.get('quantity')\n",
        "\n",
        "        # Ensure product name, manufacturer, and quantity are not None for shipment item\n",
        "        if any(val is None for val in [product_name, manufacturer, quantity]):\n",
        "            print(f\"Skipping shipment item in row {index} due to missing product/quantity data.\")\n",
        "            continue\n",
        "\n",
        "        # Get product_id from the products table (assuming it's already populated by spreadsheet0)\n",
        "        # We need to make an educated guess about product type for lookup\n",
        "        # For shipment data, product type is not explicitly given, so we need to query\n",
        "        # the 'products' table more broadly.\n",
        "        cursor.execute(\n",
        "            \"SELECT product_id FROM products WHERE name = ? AND manufacturer = ?\",\n",
        "            (product_name, manufacturer)\n",
        "        )\n",
        "        product_id_result = cursor.fetchone()\n",
        "\n",
        "        if not product_id_result:\n",
        "            print(f\"Warning: Product '{product_name}' by '{manufacturer}' not found in catalog. Skipping shipment item in row {index}.\")\n",
        "            continue\n",
        "        product_id = product_id_result[0]\n",
        "\n",
        "        try:\n",
        "            cursor.execute(\n",
        "                \"\"\"\n",
        "                INSERT INTO shipment_items (shipment_id, product_id, quantity)\n",
        "                VALUES (?, ?, ?)\n",
        "                \"\"\",\n",
        "                (shipment_id, product_id, quantity)\n",
        "            )\n",
        "            items_inserted += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Error inserting shipment item for shipment {shipping_identifier}, product {product_name}: {e}\")\n",
        "\n",
        "    conn.commit()\n",
        "    print(f\"Finished processing shipment data. {shipments_processed} unique shipments processed, {items_inserted} shipment items inserted.\")\n",
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    db_file_path = os.path.join(SPREADSHEET_DIR, DATABASE_NAME)\n",
        "    spreadsheet0_path = os.path.join(SPREADSHEET_DIR, 'spreadsheet0.xlsx')\n",
        "    spreadsheet1_path = os.path.join(SPREADSHEET_DIR, 'spreadsheet1.xlsx')\n",
        "    spreadsheet2_path = os.path.join(SPREADSHEET_DIR, 'spreadsheet2.xlsx')\n",
        "\n",
        "    # 1. Setup Database\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = setup_database(db_file_path)\n",
        "\n",
        "        # 2. Process Spreadsheet 0 (Product Catalog)\n",
        "        process_spreadsheet0(spreadsheet0_path, conn)\n",
        "\n",
        "        # 3. Process Spreadsheets 1 & 2 (Shipments and Shipment Items)\n",
        "        process_shipment_data(spreadsheet1_path, spreadsheet2_path, conn)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during database population: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "            print(\"Database connection closed.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An unexpected error occurred during database population: unable to open database file\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "o2SBlcWtrFVr",
        "outputId": "bf9c32f1-4ca9-4945-8636-6c051b97e2c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}